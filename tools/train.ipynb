{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import utils.dataset as myDataset\n",
    "import utils.loss as myLoss\n",
    "import model.model as myModel\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "arg_batchSize = 32\n",
    "arg_nEpoch = 10\n",
    "arg_pretrainedModel = None\n",
    "# arg_pretrainedModel = \"../model/pretrainedModel/final_facedet.pt\"\n",
    "arg_workers = 12\n",
    "arg_dataset = \"../data/\"\n",
    "arg_split = \"train\"\n",
    "arg_outName = \"facedet.pt\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataset = myDataset.FaceDataset(datapath = arg_dataset, split = arg_split)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle = True, batch_size = arg_batchSize, \\\n",
    "                                         num_workers = arg_workers, drop_last = False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "7050it [01:17, 91.06it/s] \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "writer = SummaryWriter(\"../log/scene\")\n",
    "\n",
    "print(\"length of dataset: %s\" % (len(dataloader)))\n",
    "batch_num = len(dataloader)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = myModel.FaceKeypointModel()\n",
    "model.apply(myModel.weights_init)\n",
    "\n",
    "if arg_pretrainedModel != None:\n",
    "    model.load_state_dict(torch.load(\"../model/\" + arg_pretrainedModel))\n",
    "    print(\"Use model from ../model/\" + arg_pretrainedModel)\n",
    "else:\n",
    "    print(\"Use new model\")\n",
    "\n",
    "if not os.path.exists(\"../model/pretrainedModel\"):\n",
    "    os.makedirs(\"../model/pretrainedModel\")\n",
    "\n",
    "model.cuda()\n",
    "# model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9, 0.999))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "length of dataset: 221\n",
      "Use new model\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for epoch in tqdm(range(arg_nEpoch)):\n",
    "    for i, data in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        image, anno, gtmap= data\n",
    "        image, anno, gtmap= image.to(device,  dtype=torch.float), anno.to(device), gtmap.to(device, dtype=torch.float)\n",
    "        image = image/255.0\n",
    "        \n",
    "        heatMap = model(image)\n",
    "        \n",
    "        loss = myLoss.calLossMSE(heatMap, anno, gtmap)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar(\"training loss\", loss.item(), epoch*len(dataloader) + i)\n",
    "\n",
    "    print(\"[ epoch: %d/%d  batch: %d/%d ]  loss: %f\" % (epoch, arg_nEpoch, i + 1, batch_num, loss.item()))\n",
    "    if epoch % 5 == 4:\n",
    "        torch.save(model.state_dict(), \"../model/pretrainedModel/epo\" + str(epoch) + arg_outName)\n",
    "        print(\"Model saved at ../model/pretrainedModel/epo\" + str(epoch) + arg_outName)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [01:53,  1.95it/s]\n",
      " 10%|█         | 1/10 [01:54<17:10, 114.51s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ epoch: 0/10  batch: 221/221 ]  loss: 0.232973\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [01:42,  2.16it/s]\n",
      " 20%|██        | 2/10 [03:37<14:22, 107.76s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ epoch: 1/10  batch: 221/221 ]  loss: 0.269217\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "197it [09:55,  3.02s/it]\n",
      " 20%|██        | 2/10 [13:33<54:15, 406.99s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0b1a707c4f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ epoch: %d/%d  batch: %d/%d ]  loss: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_nEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(model.state_dict(), \"../model/pretrainedModel/final_test_\" + arg_outName)\n",
    "print(\"Model saved at ../model/pretrainedModel/final_\" + arg_outName)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b89933b722b04da96b1a08b87050e378198849112699c322f4a458dc0a02ab73"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}